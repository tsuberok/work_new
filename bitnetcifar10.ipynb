{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5441a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:28.091054Z",
     "iopub.status.busy": "2026-02-13T19:13:28.090563Z",
     "iopub.status.idle": "2026-02-13T19:13:45.687195Z",
     "shell.execute_reply": "2026-02-13T19:13:45.685932Z"
    },
    "papermill": {
     "duration": 17.604153,
     "end_time": "2026-02-13T19:13:45.689832",
     "exception": false,
     "start_time": "2026-02-13T19:13:28.085679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\r\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7e6836e907f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import Tensor\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from torch.utils.data import Dataset\n",
    "import json \n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "cpu_device = torch.device('cpu')\n",
    "cuda_device = torch.device('cuda')\n",
    "DTYPENET = torch.float32\n",
    "DTYPEDATA = torch.float16 #maybe even float16. Sadly it doesn't do anything\n",
    "DEVICE = cpu_device\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = cuda_device\n",
    "    torch.cuda.empty_cache()\n",
    "print(DEVICE)\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb9b284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:45.699196Z",
     "iopub.status.busy": "2026-02-13T19:13:45.698624Z",
     "iopub.status.idle": "2026-02-13T19:13:54.244053Z",
     "shell.execute_reply": "2026-02-13T19:13:54.242468Z"
    },
    "papermill": {
     "duration": 8.552314,
     "end_time": "2026-02-13T19:13:54.246203",
     "exception": false,
     "start_time": "2026-02-13T19:13:45.693889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:03<00:00, 44.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f58beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:54.260313Z",
     "iopub.status.busy": "2026-02-13T19:13:54.259898Z",
     "iopub.status.idle": "2026-02-13T19:13:54.293160Z",
     "shell.execute_reply": "2026-02-13T19:13:54.291983Z"
    },
    "papermill": {
     "duration": 0.042739,
     "end_time": "2026-02-13T19:13:54.295242",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.252503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BitConv2d(nn.Conv2d):\n",
    "    def __init__(self, isDepth, *args, num_bits: int = 2, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_bits = num_bits\n",
    "\n",
    "        self.eps:float = 1e-5\n",
    "        self.quantization_range: int = 2 ** (num_bits - 1) # Q_b in the paper\n",
    "        self.isDepth = isDepth\n",
    "\n",
    "    def ste_weights(self, weights_gamma: float) -> Tensor:\n",
    "        eps: float = 1e-7\n",
    "        scaled_weights:Tensor = self.weight / (weights_gamma + eps)\n",
    "        bin_weights_no_grad: Tensor = torch.clamp(torch.round(scaled_weights), min=-1, max=1)\n",
    "        bin_weights_with_grad: Tensor = (bin_weights_no_grad - self.weight).detach() + self.weight\n",
    "        return bin_weights_with_grad\n",
    "\n",
    "\n",
    "    def binarize_weights(self, weights_gamma: float) -> Tensor:\n",
    "        binarized_weights = self.ste_weights(weights_gamma)\n",
    "        return binarized_weights\n",
    "\n",
    "\n",
    "    def quantize_activations(self, _input:Tensor, input_gamma: float) -> Tensor:\n",
    "        # Equation 4 BitNet paper\n",
    "        quantized_input = torch.clamp(\n",
    "                _input * self.quantization_range / input_gamma,\n",
    "                -self.quantization_range + self.eps,\n",
    "                self.quantization_range - self.eps,\n",
    "            )\n",
    "        #quantized_input = torch.floor(quantized_input)\n",
    "        return quantized_input\n",
    "\n",
    "\n",
    "    def dequantize_activations(self, _input: Tensor, input_gamma: float, beta: float) -> Tensor:\n",
    "        return _input * input_gamma * beta / self.quantization_range\n",
    "\n",
    "\n",
    "    def forward(self, _input: Tensor) -> Tensor:\n",
    "        # print(\"input mean and sd = \", torch.mean(_input).item(), torch.std(_input).item())\n",
    "        # print(\"max and min = \", torch.max(_input).item(), torch.min(_input).item())\n",
    "        normalized_input: Tensor = nn.functional.layer_norm(_input, (_input.shape[1:]))\n",
    "        input_gamma: float = normalized_input.abs().max().item()\n",
    "        # print(\"absmax = \", input_gamma)\n",
    "        weight_abs_mean: float = self.weight.abs().mean().item()\n",
    "\n",
    "        binarized_weights = self.binarize_weights(weight_abs_mean)\n",
    "        input_quant = self.quantize_activations(normalized_input, input_gamma)\n",
    "        output = torch.nn.functional.conv2d(\n",
    "            input=input_quant,\n",
    "            weight=binarized_weights,\n",
    "            bias=self.bias,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups\n",
    "        )#input=input_quant\n",
    "        # if torch.any(torch.abs(output) >= 128):\n",
    "        #     print(\"alarm! int8 overflow\")\n",
    "        if not self.isDepth:\n",
    "            output = self.dequantize_activations(output, input_gamma, weight_abs_mean)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class BitLinear(nn.Linear):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        bias: bool = True,\n",
    "        num_bits: int = 8,\n",
    "    ):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.eps:float = 1e-5\n",
    "        self.quantization_range: int = 2 ** (num_bits - 1) # Q_b in the paper\n",
    "\n",
    "\n",
    "    def ste_weights(self, weights_gamma: float) -> Tensor:\n",
    "        eps: float = 1e-7\n",
    "        scaled_weights:Tensor = self.weight / (weights_gamma + eps)\n",
    "        bin_weights_no_grad: Tensor = torch.clamp(torch.round(scaled_weights), min=-1, max=1)\n",
    "        bin_weights_with_grad: Tensor = (bin_weights_no_grad - self.weight).detach() + self.weight\n",
    "        return bin_weights_with_grad\n",
    "\n",
    "\n",
    "    def binarize_weights(self, weights_gamma: float) -> Tensor:\n",
    "        binarized_weights = self.ste_weights(weights_gamma)\n",
    "        return binarized_weights\n",
    "\n",
    "\n",
    "    def quantize_activations(self, _input:Tensor, input_gamma: float) -> Tensor:\n",
    "        # Equation 4 BitNet paper\n",
    "        quantized_input = torch.clamp(\n",
    "                _input * self.quantization_range / input_gamma,\n",
    "                -self.quantization_range + self.eps,\n",
    "                self.quantization_range - self.eps,\n",
    "            )\n",
    "        quantized_input = torch.floor(quantized_input)\n",
    "        return quantized_input\n",
    "\n",
    "\n",
    "    def dequantize_activations(self, _input: Tensor, input_gamma: float, beta: float) -> Tensor:\n",
    "        return _input * input_gamma * beta / self.quantization_range\n",
    "\n",
    "\n",
    "    def forward(self, _input: Tensor) -> Tensor:\n",
    "        normalized_input: Tensor =nn.functional.layer_norm(_input,(_input.shape[1:]))\n",
    "        input_gamma: float = normalized_input.abs().max().item()\n",
    "        weight_abs_mean: float = self.weight.abs().mean().item()\n",
    "\n",
    "        binarized_weights = self.binarize_weights(weight_abs_mean)\n",
    "        input_quant = self.quantize_activations(normalized_input, input_gamma)\n",
    "        output = torch.nn.functional.linear(input_quant, binarized_weights, self.bias)#input_quant\n",
    "        output = self.dequantize_activations(output, input_gamma, weight_abs_mean)\n",
    "\n",
    "        return output\n",
    "\n",
    "class CNNBLOCK_DS(nn.Module):#i should use more *ags and **kwargs\n",
    "    def __init__(self, in_channels_, out_channels_,\n",
    "                 kernel_size_=3, stride_=1, \n",
    "                 padding_=1, bias_=False):\n",
    "        super().__init__()\n",
    "        self.conv_depth = BitConv2d(isDepth = True,in_channels = in_channels_, \n",
    "                                    out_channels =in_channels_, \n",
    "                                    kernel_size =kernel_size_, \n",
    "                                    stride = stride_, \n",
    "                                    padding = padding_, \n",
    "                                    dilation = 1,\n",
    "                                    groups =in_channels_,\n",
    "                                    bias = bias_)\n",
    "        self.conv_sep = BitConv2d(isDepth = False, in_channels = in_channels_, \n",
    "                                  out_channels = out_channels_, \n",
    "                                  kernel_size=1, \n",
    "                                  stride = 1,\n",
    "                                  padding= 0, \n",
    "                                  dilation=1,\n",
    "                                  groups = 1,\n",
    "                                  bias=False )\n",
    "        self.lrlu = nn.LeakyReLU(0.1)\n",
    "    def forward(self, x):\n",
    "        return self.lrlu(self.conv_sep(self.conv_depth(x)))#i think we need bn here\n",
    "        \n",
    "\n",
    "class RESBLOCK(nn.Module):\n",
    "    def __init__(self, list_of_params):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        for block in list_of_params:\n",
    "            in_channels_ = block[0]\n",
    "            out_channels_ = block[1]\n",
    "            modules.append(CNNBLOCK_DS(in_channels_, out_channels_))\n",
    "        self.suka = nn.Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        return x + self.suka(x)\n",
    "\n",
    "class YOLONET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.convBlock1 = CNNBLOCK_DS(3, 64)\n",
    "        \n",
    "        #we need 5 32 layers, 5 64 layers, 5 128 layers and 5 256 layers. Don't forget to maxpool\n",
    "        self.resblock64_1 = RESBLOCK([[64, 64], [64,64] ])#how many layers should i have in my resblock???\n",
    "        self.resblock64_2 = RESBLOCK([[64, 64], [64,64] ])\n",
    "        self.resblock64_3 = RESBLOCK([[64, 64], [64,64] ])\n",
    "        self.resblock64_4 = RESBLOCK([[64, 64], [64,64] ])\n",
    "        self.resblock64_5 = RESBLOCK([[64, 64], [64,64] ])\n",
    "\n",
    "        #how do we upscale??\n",
    "        self.convInter_64_128 = CNNBLOCK_DS(64, 128)\n",
    "        self.resblock128_1 = RESBLOCK([[128, 128], [128, 128]])\n",
    "        self.resblock128_2 = RESBLOCK([[128, 128], [128, 128]])\n",
    "        self.resblock128_3 = RESBLOCK([[128, 128], [128, 128]])\n",
    "        self.resblock128_4 = RESBLOCK([[128, 128], [128, 128]])\n",
    "        self.resblock128_5 = RESBLOCK([[128, 128], [128, 128]])\n",
    "        self.convInter_128_256 = CNNBLOCK_DS(128, 256)\n",
    "        self.resblock256_1 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        self.resblock256_2 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        self.resblock256_3 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        self.resblock256_4 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        self.resblock256_5 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        self.resblock256_6 = RESBLOCK([[256, 256], [256, 256]])\n",
    "        \n",
    "        #self.convLast = nn.Conv2d(128, 16, 1 padding=0, bias=False)#how do we ensure we have [:, 16, 13, 13] output tensor????\n",
    "        self.avgPool = nn.AvgPool2d(2,3)\n",
    "        self.fc = BitLinear(256, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.convBlock1(x)\n",
    "        x = self.resblock64_1(x)\n",
    "        x = self.resblock64_2(x)\n",
    "        x = self.resblock64_3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock64_4(x)\n",
    "        x = self.resblock64_5(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.convInter_64_128(x)\n",
    "        x = self.resblock128_1(x)\n",
    "        x = self.resblock128_2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock128_3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock128_4(x)\n",
    "        x = self.resblock128_5(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.convInter_128_256(x)\n",
    "        x = self.resblock256_1(x)\n",
    "        x = self.resblock256_2(x)\n",
    "        x = self.resblock256_3(x)\n",
    "        x = self.resblock256_4(x)\n",
    "        x = self.resblock256_5(x)\n",
    "        x = self.resblock256_6(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        #print('1', x.shape)\n",
    "        x = self.fc(x)#F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df4872",
   "metadata": {
    "papermill": {
     "duration": 0.005543,
     "end_time": "2026-02-13T19:13:54.306698",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.301155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e3b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:54.319982Z",
     "iopub.status.busy": "2026-02-13T19:13:54.319549Z",
     "iopub.status.idle": "2026-02-13T19:13:54.398461Z",
     "shell.execute_reply": "2026-02-13T19:13:54.397101Z"
    },
    "papermill": {
     "duration": 0.088128,
     "end_time": "2026-02-13T19:13:54.400646",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.312518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resResResNet = YOLONET().to(DTYPENET)\n",
    "for layer in resResResNet.modules():\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        layer.float()\n",
    "\n",
    "resResResNet = resResResNet.to(DEVICE)\n",
    "criterionRes = nn.CrossEntropyLoss()\n",
    "optimizerRes = optim.Adam(resResResNet.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5c1e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:54.414694Z",
     "iopub.status.busy": "2026-02-13T19:13:54.414188Z",
     "iopub.status.idle": "2026-02-13T19:13:54.418779Z",
     "shell.execute_reply": "2026-02-13T19:13:54.417707Z"
    },
    "papermill": {
     "duration": 0.013628,
     "end_time": "2026-02-13T19:13:54.420620",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.406992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    resResResNet.load_state_dict(torch.load(\"/kaggle/input/weaintsuffering/theCIFARbitnetWithNoBatchNorm (1).pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ff482e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:54.434224Z",
     "iopub.status.busy": "2026-02-13T19:13:54.433784Z",
     "iopub.status.idle": "2026-02-13T19:13:54.441239Z",
     "shell.execute_reply": "2026-02-13T19:13:54.440020Z"
    },
    "papermill": {
     "duration": 0.01636,
     "end_time": "2026-02-13T19:13:54.443130",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.426770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        print(\"EPOCH\",epoch+1)\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "            optimizerRes.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "            outputs = resResResNet(inputs.to(DEVICE))\n",
    "            loss = criterionRes(outputs, labels.to(DEVICE))\n",
    "            if torch.any(torch.isnan(loss)).item() or torch.any(torch.isinf(loss)).item():\n",
    "                print('NAN OR INF', loss.item())\n",
    "            loss.backward()\n",
    "            optimizerRes.step()\n",
    "\n",
    "        # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    \n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    torch.save(resResResNet.state_dict(), '/kaggle/working/theCIFARbitnetWithNoBatchNorm.pt')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3353b864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:13:54.458153Z",
     "iopub.status.busy": "2026-02-13T19:13:54.457671Z",
     "iopub.status.idle": "2026-02-13T19:17:14.707183Z",
     "shell.execute_reply": "2026-02-13T19:17:14.705950Z"
    },
    "papermill": {
     "duration": 200.2658,
     "end_time": "2026-02-13T19:17:14.716031",
     "exception": false,
     "start_time": "2026-02-13T19:13:54.450231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = resResResNet(images.to(DEVICE))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(DEVICE)).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6834787,
     "sourceId": 10982330,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 231.958803,
   "end_time": "2026-02-13T19:17:16.452281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-13T19:13:24.493478",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
